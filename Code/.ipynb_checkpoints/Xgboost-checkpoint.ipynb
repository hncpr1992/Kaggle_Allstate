{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data load in and transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.options.display.max_columns = 200\n",
    "pd.options.display.max_rows = 200\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train = pd.read_csv(\"../Data/train.csv\")\n",
    "test = pd.read_csv(\"../Data/test.csv\")\n",
    "loss = train[\"loss\"]\n",
    "train_id = train[\"id\"]\n",
    "test_id = test['id']\n",
    "\n",
    "del train[\"loss\"]\n",
    "del train[\"id\"]\n",
    "del test[\"id\"]\n",
    "\n",
    "# remove NZV\n",
    "catFeature = []\n",
    "for i in range(1,116):\n",
    "    catFeature.append(\"cat%i\" % i)\n",
    "\n",
    "ratio = []\n",
    "\n",
    "for col in catFeature:\n",
    "    max_ratio = train[col].value_counts().max()/len(train[col])\n",
    "    ratio.append(max_ratio)\n",
    "\n",
    "rmFeature = np.array(catFeature)[np.array(ratio)>=1]\n",
    "\n",
    "for i in rmFeature:\n",
    "    del train[i]\n",
    "    del test[i]    \n",
    "\n",
    "# reduce the number of categories in some cat variable\n",
    "train[\"cat109\"] = train[\"cat109\"].apply(lambda x: \"other\" if x not in (\"BI\",\"AB\") else x)\n",
    "test[\"cat109\"] = test[\"cat109\"].apply(lambda x: \"other\" if x not in (\"BI\",\"AB\") else x)\n",
    "\n",
    "cat_110_domi = train.cat110.value_counts().index[(train.cat110.value_counts()/len(train.cat109))>0.01].values\n",
    "train[\"cat110\"] = train[\"cat110\"].apply(lambda x: \"other\" if x not in cat_110_domi else x)\n",
    "test[\"cat109\"] = test[\"cat109\"].apply(lambda x: \"other\" if x not in (\"BI\",\"AB\") else x)\n",
    "cat_113_domi = train.cat113.value_counts().index[(train.cat113.value_counts()/len(train.cat113))>0.005].values\n",
    "train[\"cat113\"] = train[\"cat113\"].apply(lambda x: \"other\" if x not in cat_113_domi else x)\n",
    "test[\"cat109\"] = test[\"cat109\"].apply(lambda x: \"other\" if x not in (\"BI\",\"AB\") else x)\n",
    "\n",
    "# assign train to X\n",
    "X = train\n",
    "\n",
    "# Categorize the continuous variables\n",
    "breakpoint_normal = [-0.01,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0]\n",
    "breakpoint2 = [-0.01,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,1.0]\n",
    "breakpoint4 = [-0.01,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0]\n",
    "breakpoint5 = [-0.01,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0]\n",
    "breakpoint8 = [-0.01,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0]\n",
    "breakpoint14 = [-0.01,0.2,0.3,0.4,0.5,0.6,0.7,0.8,1.0]\n",
    "breakpoint_special = [breakpoint2,breakpoint4,breakpoint5,breakpoint8,breakpoint14]\n",
    "\n",
    "columns_normal_cut = ['cont1', 'cont3', 'cont6', 'cont7', 'cont9', 'cont10', 'cont11', 'cont12', 'cont13',]\n",
    "columns_special_cut = ['cont2','cont4','cont5','cont8','cont14']\n",
    "\n",
    "# normal cut\n",
    "for i in columns_normal_cut:\n",
    "    X[i] = pd.cut(X[i],breakpoint_normal)\n",
    "    test[i] = pd.cut(test[i],breakpoint_normal)\n",
    "\n",
    "# special cut\n",
    "k = 0\n",
    "for i in columns_special_cut:\n",
    "    X[i] = pd.cut(X[i],breakpoint_special[k])\n",
    "    test[i] = pd.cut(test[i],breakpoint_special[k])\n",
    "\n",
    "test.index = range(188318,188318+125546)\n",
    "ALL = pd.concat([X,test],axis=0)\n",
    "\n",
    "# transform the cats to dummy\n",
    "obj = ALL.dtypes.index[ALL.dtypes.apply(lambda x: x in [\"object\",\"category\"])]\n",
    "for i in obj:\n",
    "    new_cat = pd.get_dummies(ALL[i],prefix=i,drop_first=True)\n",
    "    del ALL[i]\n",
    "    ALL = pd.concat([ALL,new_cat],axis = 1)\n",
    "\n",
    "X = ALL.ix[:188317,:]\n",
    "test = ALL.ix[188318:,:]\n",
    "del ALL\n",
    "\n",
    "X = X.as_matrix()\n",
    "test = test.as_matrix()\n",
    "loss = loss.as_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gbm = xgb.XGBRegressor(max_depth=3, learning_rate=0.01, n_estimators=100,silent=False,nthread=-1,\n",
    "                      seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss_log = np.log(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gbm.fit(X,loss_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred_log = gbm.predict(test)\n",
    "y_pred = np.exp(y_pred_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "export = pd.DataFrame({\"id\":test_id,\"loss\":y_pred})\n",
    "export.to_csv(\"../Sub/submission_gbm1.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
